2x2x2 env (change depth of policy param in respective files)
PPO: `python ppo.py`
PPO + Manhatten Distance: `python ppo_distance.py`
Train NN distance model: `python ctg_function.py` (change env name before running, pickled trained model found in drive link)
PPO + NN distance: `python ppo_distance_nn.py`

Skewb env (change depth of policy param in respective files)
PPO: `python skewb_ppo.py`
Train NN distance model: `python ctg_function.py` (change env name before running, pickled trained model found in drive link)
PPO + NN distance: `python skewb_ppo_distance_nn.py`

Pyraminx env (change depth of policy param in respective files)
Train NN distance model: `python ctg_function.py` (change env name before running, pickled trained model found in drive link)
PPO + NN distance: `python pyraminx_ppo_distance_nn.py`

reward model pickled files as well as data used to plot figures found here: https://drive.google.com/drive/folders/1xUNeXYXgrHpvxL4QS-INhaYKMWy8sFaM?usp=share_link


